---
layout: about
title: about
permalink: /
subtitle: MSE Computer Science Student & AI Researcher | Johns Hopkins University

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false
  more_info: >
    <p>Graduate Researcher</p>
    <p>Johns Hopkins University</p>
    <p>Baltimore, MD</p>

selected_papers: true
social: true

announcements:
  enabled: true
  scrollable: true
  limit: 7
---

> **I design efficient machine learning and language technologies for healthcare and low-resource settings.**

I am a Master's student in Computer Science at Johns Hopkins University and an AI researcher focusing on efficiency-centric machine learning, natural language processing, and healthcare applications. I am interested in models that reason, translate, and make predictions under realistic compute, memory, and data constraints.

At Johns Hopkins, I am advised by **[Prof. Anjalie Field](https://anjalief.github.io/)** and work with **[Prof. Philipp Koehn](https://www.cs.jhu.edu/~phi/)** on low-resource machine translation and reference-free evaluation, developing reinforcement learning methods that use paraphrase consensus instead of parallel corpora. As a research intern at **[Mayo Clinic](https://www.mayo.edu/)**, I build end-to-end clinical ML pipelines for blood utilization forecasting and biomarker detection, with an emphasis on deployable systems that integrate into real hospital workflows.

Previously, at North South University, I completed my undergraduate thesis on hybrid quantum-classical machine learning under **[Prof. Mahdy Rahman Chowdhury](https://scholar.google.com/citations?user=PxNOguMAAAAJ)**, who received the **ICO Galileo Galilei Medal Award** in 2023. I currently work with Prof. Mahdy as an AI Research Assistant at Mahdy Research Academy, where I lead projects on model compression for clinical language models (*OptimCLM*), efficient deep metric learning (*Shadow Loss*), hybrid quantum-classical architectures, and multimodal medical imaging models. My work has appeared in venues such as **IEEE ICDM**, **Pattern Recognition Letters**, **International Journal of Medical Informatics**, **PLOS ONE**, and **IEEE Access**, along with several manuscripts currently under review at top-tier conferences and journals.

---

### Current Positions

- **Graduate Researcher**, Center for Language and Speech Processing (CLSP), Johns Hopkins University
- **Data Science / AI Research Intern**, Mayo Clinic (Transfusion Medicine & Pathology)
- **AI Research Assistant & Mentor**, Mahdy Research Academy (remote)

---

### Research Areas

<div class="row mt-3">
    <div class="col-sm-6 mt-3 mt-md-0 mb-4">
        <strong>Efficient ML & Model Compression</strong><br>
        <small>Knowledge distillation, pruning, quantization for edge deployment</small>
    </div>
    <div class="col-sm-6 mt-3 mt-md-0 mb-4">
        <strong>Low-Resource & Multilingual NLP</strong><br>
        <small>Machine translation, reference-free evaluation, cross-lingual learning</small>
    </div>
    <div class="col-sm-6 mt-3 mt-md-0 mb-4">
        <strong>Clinical Decision Support & Medical Imaging</strong><br>
        <small>Healthcare AI, biomarker detection, clinical outcome prediction</small>
    </div>
    <div class="col-sm-6 mt-3 mt-md-0 mb-4">
        <strong>Hybrid Quantum-Classical Learning</strong><br>
        <small>Knowledge transfer to quantum neural networks, efficient quantum architectures</small>
    </div>
</div>

---

### Featured Research

<div class="row mt-3">
    <div class="col-md-6 mb-4">
        <div class="card h-100" style="border-left: 4px solid var(--global-theme-color);">
            <div class="card-body">
                <h5 class="card-title"><a href="/projects/optimclm/">OptimCLM</a></h5>
                <p class="card-text"><small class="text-muted">IJMI 2025</small></p>
                <p class="card-text">Optimizing clinical language models via knowledge distillation, pruning, and quantization. Achieved <strong>22.9× compression</strong> with 98% performance retention.</p>
                <a href="https://github.com/junayed-hasan/Clinical-Language-Model-Distillation-Pruning-Quantization" class="btn btn-sm btn-outline-primary"><i class="fab fa-github"></i> Code</a>
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S1386505624004271" class="btn btn-sm btn-outline-secondary"><i class="fas fa-file-alt"></i> Paper</a>
            </div>
        </div>
    </div>
    <div class="col-md-6 mb-4">
        <div class="card h-100" style="border-left: 4px solid var(--global-theme-color);">
            <div class="card-body">
                <h5 class="card-title"><a href="/projects/hadasmilenet/">HadaSmileNet</a></h5>
                <p class="card-text"><small class="text-muted">IEEE ICDM 2025</small></p>
                <p class="card-text">Hadamard fusion of handcrafted and deep-learning features for genuine smile recognition. <strong>Oral + Poster</strong> at ICDM 2025.</p>
                <a href="https://github.com/junayed-hasan/smile-recognition-fusion" class="btn btn-sm btn-outline-primary"><i class="fab fa-github"></i> Code</a>
                <a href="https://arxiv.org/abs/2509.18550" class="btn btn-sm btn-outline-secondary"><i class="fas fa-file-alt"></i> Paper</a>
            </div>
        </div>
    </div>
    <div class="col-md-6 mb-4">
        <div class="card h-100" style="border-left: 4px solid var(--global-theme-color);">
            <div class="card-body">
                <h5 class="card-title"><a href="/projects/bridging_quantum_classical/">Bridging Quantum-Classical ML</a></h5>
                <p class="card-text"><small class="text-muted">IEEE TQE (Under Review)</small></p>
                <p class="card-text">First knowledge distillation framework bridging classical neural networks with quantum circuits. <strong>12 preprint citations</strong>.</p>
                <a href="https://github.com/junayed-hasan/Quantum-Machine-Learning" class="btn btn-sm btn-outline-primary"><i class="fab fa-github"></i> Code</a>
                <a href="https://arxiv.org/abs/2311.13810" class="btn btn-sm btn-outline-secondary"><i class="fas fa-file-alt"></i> Preprint</a>
            </div>
        </div>
    </div>
    <div class="col-md-6 mb-4">
        <div class="card h-100" style="border-left: 4px solid var(--global-theme-color);">
            <div class="card-body">
                <h5 class="card-title"><a href="/projects/shadow_loss/">Shadow Loss</a></h5>
                <p class="card-text"><small class="text-muted">CVPR 2026 (Under Review)</small></p>
                <p class="card-text">Memory-linear deep metric learning reducing complexity from O(N²) to O(N) while accelerating convergence <strong>1.5-2×</strong>.</p>
                <a href="https://arxiv.org/abs/2311.14012" class="btn btn-sm btn-outline-secondary"><i class="fas fa-file-alt"></i> Preprint</a>
            </div>
        </div>
    </div>
</div>

<p class="text-center mt-2"><a href="/projects/" class="btn btn-primary">View All Projects →</a></p>
